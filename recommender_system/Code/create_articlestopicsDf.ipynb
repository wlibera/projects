{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "with open(\"data/articles_cleaned.pkl\", \"rb\") as file:\n",
    "    articles = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickleFiles/LDA_modelList_15_30_by_5.pkl\", \"rb\") as file:\n",
    "    topicModel = pickle.load(file)\n",
    "\n",
    "topicModel = topicModel[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "def prepareForLDA(list_tokenized, stopwords = []):\n",
    "    \"\"\"\n",
    "    Prepares a dictionary and a corpus for LDA\n",
    "    Parameters:\n",
    "        - list_tokenized: a list of tokenized documents (i.e. a list of lists of tokens)\n",
    "        - stopwords: words that still need to be excluded from the list_tokenized\n",
    "    \"\"\"\n",
    "    # make a new list_tokenized without the stopwords\n",
    "    list_stopwordsExcluded = []\n",
    "\n",
    "    for doc in list_tokenized:\n",
    "        list_stopwordsExcluded.append([word for word in doc if word not in stopwords])\n",
    "\n",
    "    dictionary = Dictionary(list_stopwordsExcluded) # get the vocabulary\n",
    "\n",
    "    corpus = [dictionary.doc2bow(text) for text in list_stopwordsExcluded]\n",
    "\n",
    "    return dictionary, corpus\n",
    "\n",
    "\n",
    "articles_dictionaryLDA, articles['corpusLDA'] = prepareForLDA(articles['cleaned_article'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names of topics in model object\n",
    "topicModel_names = {0: 'sports', 1: 'war', 2: 'EUPolitics', 3: 'crimes', 4: '4 - NaN', 5: 'israelPalestine', 6: 'immigration', 7: 'showArts', 8: '8 - NaN', 9: '9 - NaN', 10: 'spaceTravel', 11: 'elections', 12: 'instAbuse', 13: 'protest', 14: 'terrorism', 15: '15 - NaN', 16: '16 - NaN', 17: 'economy', 18: '18 - NaN', 19: '19 - NaN', 20: 'USPolitics', 21: 'britishBrexit', 22: 'covid', 23: 'climateChange', 24: 'naturalDisasters'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a topics dataframe for all articles\n",
    "\n",
    "def topics(currentArticle):\n",
    "    currentArticle_bow = articles.iloc[currentArticle]['corpusLDA'] # make bow representation of current article\n",
    "    topics_article = list(topicModel.get_document_topics(currentArticle_bow, minimum_probability = 0.05)) # get list of topic distributions of current article\n",
    "    topics_article = [(topicModel_names[t[0]], t[1]) for t in topics_article] # get topic names\n",
    "\n",
    "    topics_distribution = {'EUPolitics': 0, 'crimes': 0, 'israelPalestine':0, 'immigration': 0, 'sports': 0, 'war': 0, 'climateChange': 0, 'showArts': 0, 'covid': 0, 'britishBrexit': 0, 'instAbuse': 0, 'spaceTravel': 0, 'protest': 0, 'terrorism': 0, 'USPolitics': 0, 'naturalDisasters': 0, 'elections': 0, 'economy': 0}\n",
    "    topics_distribution.update(topics_article)\n",
    "\n",
    "    for key in list(topics_distribution.keys()):\n",
    "        if 'NaN' in key: # delete topics that could not be manually identified (and thus are not included in the interest data)\n",
    "            del topics_distribution[key]\n",
    "\n",
    "    return dict(topics_distribution)\n",
    "\n",
    "\n",
    "# create a topics dataframe for all articles\n",
    "global articles_topics\n",
    "articles_topics = pd.DataFrame(0, index = articles.index, columns = topicModel_names.values())\n",
    "\n",
    "for idx in range(len(articles)):\n",
    "    articles_topics.iloc[idx] = topics(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_topics.to_csv('data/articles_topics.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
